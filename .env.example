# LLM Provider Configuration
MODEL_PROVIDER=groq  # Options: groq, openai
MODEL_NAME=llama-3.3-70b-versatile
TEMPERATURE=0.3
MAX_TOKENS=2000

# API Keys
GROQ_API_KEY=your_groq_api_key_here
GH_TOKEN=your_github_token_here
TAVILY_API_KEY=your_tavily_api_key_here

# OpenAI (optional - only if using openai provider)
OPENAI_API_KEY=your_openai_api_key_here

# Application Settings
LOG_LEVEL=INFO
MAX_RETRIES=3
TIMEOUT=30

# Retry Configuration (optional - defaults provided)
RETRY_BACKOFF_FACTOR=2.0
RETRY_INITIAL_DELAY=1.0
RETRY_MAX_DELAY=60.0

# LangSmith (optional - for observability)
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=drrepo
LANGCHAIN_TRACING_V2=false
